"""
V4: ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜

LightGBM, XGBoost, RandomForest, CatBoostë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
TimeSeriesSplitì„ ì‚¬ìš©í•œ K-Fold êµì°¨ê²€ì¦ì„ ì ìš©í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple
import json
from datetime import datetime

from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import lightgbm as lgb
import xgboost as xgb

try:
    from catboost import CatBoostRegressor
    HAS_CATBOOST = True
except ImportError:
    HAS_CATBOOST = False

from .base_model import load_featured_data, get_feature_columns


def get_models(random_state: int = 42) -> Dict[str, Any]:
    """ë¹„êµí•  ëª¨ë¸ë“¤ì„ ë°˜í™˜"""
    models = {
        "LightGBM": lgb.LGBMRegressor(
            n_estimators=500,
            learning_rate=0.05,
            num_leaves=31,
            max_depth=10,
            min_child_samples=20,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            n_jobs=-1,
            verbose=-1,
            random_state=random_state
        ),
        "XGBoost": xgb.XGBRegressor(
            n_estimators=500,
            learning_rate=0.05,
            max_depth=10,
            min_child_weight=20,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            n_jobs=-1,
            verbosity=0,
            random_state=random_state
        ),
        "RandomForest": RandomForestRegressor(
            n_estimators=300,
            max_depth=15,
            min_samples_split=20,
            min_samples_leaf=10,
            n_jobs=-1,
            random_state=random_state
        ),
        "GradientBoosting": GradientBoostingRegressor(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=8,
            min_samples_split=20,
            min_samples_leaf=10,
            random_state=random_state
        ),
    }
    
    if HAS_CATBOOST:
        models["CatBoost"] = CatBoostRegressor(
            iterations=500,
            learning_rate=0.05,
            depth=8,
            l2_leaf_reg=3,
            random_seed=random_state,
            verbose=False
        )
    
    return models


def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
    """ëª¨ë¸ í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # MAPE (0ì´ ì•„ë‹Œ ê°’ì— ëŒ€í•´)
    mask = y_true != 0
    if mask.sum() > 0:
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    else:
        mape = np.nan
    
    return {"rmse": rmse, "mae": mae, "r2": r2, "mape": mape}


def run_timeseries_cv(
    X: pd.DataFrame,
    y: pd.Series,
    model: Any,
    n_splits: int = 5
) -> Tuple[List[Dict], Dict]:
    """TimeSeriesSplitì„ ì‚¬ìš©í•œ êµì°¨ê²€ì¦"""
    tscv = TimeSeriesSplit(n_splits=n_splits)
    
    fold_results = []
    all_predictions = []
    all_actuals = []
    
    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        # ëª¨ë¸ í•™ìŠµ
        model_copy = model.__class__(**model.get_params())
        model_copy.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model_copy.predict(X_val)
        
        # í‰ê°€
        metrics = evaluate_model(y_val.values, y_pred)
        metrics["fold"] = fold + 1
        fold_results.append(metrics)
        
        all_predictions.extend(y_pred)
        all_actuals.extend(y_val.values)
    
    # ì „ì²´ í‰ê°€
    overall_metrics = evaluate_model(np.array(all_actuals), np.array(all_predictions))
    
    return fold_results, overall_metrics


def train_v4_model_comparison(
    data_path: Path,
    output_dir: Path,
    n_splits: int = 5,
    sample_size: int = None  # Noneì´ë©´ ì „ì²´ ì‚¬ìš©
) -> Dict[str, Any]:
    """
    V4 ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    TimeSeriesSplit K-Fold êµì°¨ê²€ì¦ìœ¼ë¡œ ì—¬ëŸ¬ ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤.
    """
    print("=" * 70)
    print(" V4: ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜")
    print(f" TimeSeriesSplit {n_splits}-Fold êµì°¨ê²€ì¦")
    print("=" * 70)
    
    # ë°ì´í„° ë¡œë“œ
    df = load_featured_data(data_path)
    
    # ìƒ˜í”Œë§ (ì„ íƒì )
    if sample_size and sample_size < len(df):
        df = df.iloc[:sample_size]
        print(f"\nìƒ˜í”Œë§: {sample_size:,}í–‰ ì‚¬ìš©")
    
    # Feature ì¶”ì¶œ
    feature_cols = get_feature_columns(df)
    X = df[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)
    y = df["net_passengers"]
    
    print(f"\në°ì´í„°: {len(X):,}í–‰, {len(feature_cols)} Features")
    print(f"êµì°¨ê²€ì¦: {n_splits}-Fold TimeSeriesSplit")
    
    # ëª¨ë¸ ì •ì˜
    models = get_models()
    
    # ê²°ê³¼ ì €ì¥
    results = {}
    
    print("\n" + "=" * 70)
    print(" ëª¨ë¸ë³„ í•™ìŠµ ë° í‰ê°€")
    print("=" * 70)
    
    for name, model in models.items():
        print(f"\n[{name}] í•™ìŠµ ì¤‘...")
        
        try:
            fold_results, overall_metrics = run_timeseries_cv(X, y, model, n_splits)
            
            results[name] = {
                "fold_results": fold_results,
                "overall": overall_metrics
            }
            
            print(f"  RMSE: {overall_metrics['rmse']:,.2f}")
            print(f"  MAE:  {overall_metrics['mae']:,.2f}")
            print(f"  RÂ²:   {overall_metrics['r2']:.4f}")
            
        except Exception as e:
            print(f"  [ì˜¤ë¥˜] {e}")
            results[name] = {"error": str(e)}
    
    # ê²°ê³¼ ë¹„êµ í…Œì´ë¸”
    print("\n" + "=" * 70)
    print(" ëª¨ë¸ ë¹„êµ ê²°ê³¼ (Overall)")
    print("=" * 70)
    print(f"{'ëª¨ë¸':<20} {'RMSE':>12} {'MAE':>12} {'RÂ²':>10}")
    print("-" * 60)
    
    comparison_data = []
    for name, result in results.items():
        if "overall" in result:
            m = result["overall"]
            print(f"{name:<20} {m['rmse']:>12,.2f} {m['mae']:>12,.2f} {m['r2']:>10.4f}")
            comparison_data.append({
                "model": name,
                "rmse": m["rmse"],
                "mae": m["mae"],
                "r2": m["r2"],
                "mape": m["mape"]
            })
    
    # ê²°ê³¼ ì €ì¥
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ë¹„êµ ê²°ê³¼ CSV
    comparison_df = pd.DataFrame(comparison_data).sort_values("r2", ascending=False)
    comparison_df.to_csv(output_dir / "model_comparison.csv", index=False)
    
    # ìƒì„¸ ê²°ê³¼ JSON
    with open(output_dir / "detailed_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    # ì„¤ì • ì €ì¥
    config = {
        "experiment": "V4_Model_Comparison",
        "n_splits": n_splits,
        "sample_size": sample_size or len(df),
        "n_features": len(feature_cols),
        "models": list(models.keys()),
        "timestamp": datetime.now().isoformat()
    }
    with open(output_dir / "config.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"\nê²°ê³¼ ì €ì¥: {output_dir}")
    
    # ìµœê³  ëª¨ë¸
    if comparison_data:
        best = comparison_df.iloc[0]
        print(f"\nğŸ† ìµœê³  ëª¨ë¸: {best['model']} (RÂ² = {best['r2']:.4f})")
    
    return results


if __name__ == "__main__":
    project_root = Path(__file__).parent.parent.parent
    data_path = project_root / "outputs" / "featured_data.csv"
    output_dir = project_root / "experiments" / "v4_model_comparison"
    
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìƒ˜í”Œ ì‚¬ìš© (ì „ì²´ëŠ” None)
    results = train_v4_model_comparison(data_path, output_dir, n_splits=5, sample_size=100000)







